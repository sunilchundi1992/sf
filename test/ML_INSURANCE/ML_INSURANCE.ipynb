{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "zkce45ztfef6cuaktfyy",
   "authorId": "6083229980571",
   "authorName": "SUNILREDDY559",
   "authorEmail": "sunilreddy559@gmail.com",
   "sessionId": "a43175f4-3660-43b7-8307-0d4fedbbcfd5",
   "lastEditTime": 1766749206786
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24780e9d-49a8-4530-a067-caafc99dd18c",
   "metadata": {
    "name": "cell2"
   },
   "source": [
    "## Load data into Snowflake tables\n",
    "To begin, download the full dataset (1 million rows) as a zip from this [Kaggle link](https://www.kaggle.com/datasets/sridharstreaks/insurance-data-for-machine-learning). Then unzip it to a .csv. Load that .csv into your notebook's files directory. We will pull from that csv to create a training data table and our incoming \"streamed\" data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import pandas as pd\n",
    "\n",
    "# Create the session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a391e4a-f902-4f7d-b0df-669293d9ba85",
   "metadata": {
    "name": "cell5"
   },
   "source": [
    "Load data from csv into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6f86b-274c-4127-9c4e-12debfba4f53",
   "metadata": {
    "name": "cell6",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Load full 1M dataset into dataframe\n",
    "insurance_df = pd.read_csv('insurance_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76f700-6ec7-4eb4-b174-525e94174923",
   "metadata": {
    "name": "cell7"
   },
   "source": [
    "Data cleaning, rearranging columns"
   ]
  },
  {
   "cell_type": "code",
   "id": "0062c2fb-c9e7-45e5-bb89-8a34a5ad91b8",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "insurance_df.head(2)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde22f4-f7f3-4f17-80f3-19e7399811bf",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Capitalize column names\n",
    "insurance_df.columns = insurance_df.columns.str.upper()\n",
    "\n",
    "# Rearrange columns to fit target schema\n",
    "cols = insurance_df.columns.tolist()\n",
    "cols = cols[:3] + cols[-1:] + cols[3:-1]\n",
    "insurance_df = insurance_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "id": "fba070e7-4644-476a-92f6-54f89e3e2df0",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "insurance_df.head(1)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "86267cec-f4fc-4a8e-a489-e28063634df7",
   "metadata": {
    "name": "cell8"
   },
   "source": [
    "Use the write_pandas() method to write the first 10k rows into the 'SOURCE_OF_TRUTH' table created with the SQL commands in the SQL file. The method \"returns a Snowpark DataFrame object referring to the table where the pandas DataFrame was written to.\" (Snowpark Documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a10b5-7967-486c-ba82-5ebed2887a16",
   "metadata": {
    "name": "cell9",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "source_of_truth_df = session.write_pandas(insurance_df[:10000], table_name='SOURCE_OF_TRUTH',database='INSURANCE',schema='ML_PIPE',auto_create_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951dbd7e-c183-4d94-a502-94ed852111da",
   "metadata": {
    "name": "cell10"
   },
   "source": [
    "The code below writes the remaining 990k to the INCOMING_DATA_SOURCE table to simulate data being streamed in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f137111d-ef9c-4bad-8e49-4edfbfe3189c",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "incoming_data_source_df = session.write_pandas(insurance_df[10000:], table_name='INCOMING_DATA_SOURCE',database='INSURANCE',schema='ML_PIPE',auto_create_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "id": "de259df2-628b-460a-86f8-252bb7403601",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}